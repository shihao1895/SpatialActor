# SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation
[Hao Shi](https://shihao1895.github.io/), [Bin Xie](https://xb534.github.io/), [Yingfei Liu](https://scholar.google.com/citations?user=pF9KA1sAAAAJ), [Yang Yue](https://yueyang130.github.io/), [Tiancai Wang](https://scholar.google.com/citations?user=YI0sRroAAAAJ), [Haoqiang Fan](https://scholar.google.com/citations?user=bzzBut4AAAAJ), [Xiangyu Zhang](https://scholar.google.com/citations?user=yuB-cfoAAAAJ), [Gao Huang](https://scholar.google.com/citations?user=-P9LwcgAAAAJ)

Tsinghua University, Dexmal, MEGVII, StepFun

AAAI 2026 **Oral**

> This is the code for the paper "SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation".

### ğŸ [Project Page](https://shihao1895.github.io/SpatialActor/) | ğŸ“‘[Paper]() | ğŸ¤—[Models](https://huggingface.co/collections/shihao1895/spatialactor)

## ğŸŒŸ News

- ğŸ”¥ [2025-11-8] Our paper [SpatialActor]() was accepted as an AAAI 2026 **Oral**!

## Overview

SpatialActor is a disentangled framework for robust robotic manipulation. It decouples perception into complementary high-level geometry from fine-grained but noisy raw depth and coarse but robust depth expert priors, along with low-level spatial cues and appearance semantics.

![MemoryVLA Overview](images/fig_overall.png)

## TODO

We will release the code of SpatialActor
- [ ] Code Release
- [ ] Model Weights Release
- [ ] Dataset Upload to HuggingFace

## Citation

If you find our work helpful in your research, please consider citing [our paper](). 

```bibtex
TBD
```
